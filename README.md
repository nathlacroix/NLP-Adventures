# NLP-Adventures

## Setup
Install the dependencies, with either `make install_gpu` for GPU support, or `make install_cpu`. We recommend to run this within a virtual environment with Python 3.6. When working with an LSF-based cluster (e.g. ETHZ Leonhard), this can be performed with `./utils/env_cluster.sh`.

## Data structure
The code will create (if it doesn't already exist) a folder `logs/` in which 3 folders are created during training and testing:
- `models/`: store the models saved by tensorflow.
- `summaries/`: store the summaries used by tensorboard to monitor the training and the evaluation.
- `outputs/`: store the output files generated by the network.

All the data should be in the same folder and its path is chosen by the user in the arguments of the launcher. The following files have to be present in the data folder:
- `sentences.train`: training data.
- `sentences.eval`: test data. The network will output the perplexity of every sentence.
- `sentences.continuation`: data for generation. The network will predict the end of every sentence up to a certain point (chosen by the user in the config file).
- `wordembeddings-dim100.word2vec`: (optional: only if the user wants to use a pretrained embedding) data containing a pretrained embedding. The name of this file can be modified in the config file.

## Usage
`python launcher <command> <path_to_config_file> <path_to_data_folder> <name_of_the_experiment>`

`<command>` can be of three kinds: `train` to train the network, `evaluate` to evaluate on a test set with the perplexity or `predict` to generate the end of the sentences provided in the data.
The training, testing and predicting steps have to be done separately with a different command each time. To do testing or prediction, a training with the same name of experiment has to be done before.

# NLP-Adventures

## Setup
Install the dependencies, with either `make install_gpu` for GPU support, or `make install_cpu`. We recommend to run this within a virtual environment with Python 3.6. When working with an LSF-based cluster (e.g. ETHZ Leonhard), this can be performed with `./utils/env_cluster.sh`.

## Data structure
The user can choose the location of the working directory (e.g. directly in `task2/`). This working directory should be composed of three subfolders:
- `data/`: data used by the models. It should contain the files `val_stories.csv` (validation set of the Story Cloze task) and `train_stories.csv` (training set of the Story Cloze task). It should also contain test data if the command `--test` is used (see below).
- `features/`: contains the precomputed features stored as .npz files (each entry in the .npz file should correspond to one feature and be a numpy array of dimension 1).
- `outputs/`: stores the output files generated by the models. This folder is created during the prediction if it doesn't already exist.

## Usage
`python experiment.py <base_path> <path_to_config_file> --exp_name <name_of_the_experiment> --test`

- `<base_path>`: path to the working directory described above.
- `<path_to_config_file>`: path to a config file. This config file contains for example the list of features that should be used by the model.
- `--exp_name <name_of_the_experiment>`: optional argument. Name of the experiment which will be given to the output file when a prediction on the test set is made.
- `--test`: use this flag to make a prediction on the test set (not used by default).
